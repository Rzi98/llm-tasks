{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load Llama3 quantised model with mlx** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/anaconda3/envs/splore/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 53092.46it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from mlx_lm import load, generate\n",
    "      \n",
    "model, tokenizer = load(\"mlx-community/Meta-Llama-3-8B-Instruct-4bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load Data** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversation_id    0\n",
      "message            0\n",
      "sentiment          0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Are you a fan of Google or Microsoft?</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Both are excellent technology they are helpful...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm not  a huge fan of Google, but I use it a...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_id                                            message  \\\n",
       "0                1              Are you a fan of Google or Microsoft?   \n",
       "1                1  Both are excellent technology they are helpful...   \n",
       "2                1   I'm not  a huge fan of Google, but I use it a...   \n",
       "\n",
       "                sentiment  \n",
       "0  Curious to dive deeper  \n",
       "1  Curious to dive deeper  \n",
       "2  Curious to dive deeper  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json, os\n",
    "\n",
    "df = pd.read_csv('../../data/data.csv')\n",
    "\n",
    "df = df.dropna()\n",
    "print(df.isnull().sum())\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Set Prompt** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you a fan of Google or Microsoft?\n",
      "Curious to dive deeper\n",
      "\n",
      "            <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "            INSTRUCTIONS:\n",
      "                Given the message: 'Are you a fan of Google or Microsoft?', map the sentiment to one of the following: ['Curious to dive deeper', 'Happy', 'Neutral', 'Surprised', 'Disgusted', 'Sad', 'Fearful', 'Angry'] based on the context semantic meaning.\n",
      "                Only output the sentiment label in json format.\n",
      "                {\"sentiment\": \"<label>\"}\n",
      "            <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "        \n",
      " {\"sentiment\": \"Curious to dive deeper\"}\n"
     ]
    }
   ],
   "source": [
    "message = df.message[0]\n",
    "ground_truth = df.sentiment[0]\n",
    "y_labels = df.sentiment.unique().tolist()\n",
    "\n",
    "\n",
    "output_format = '{\"sentiment\": \"<label>\"}'\n",
    "prompt = f\"\"\"\n",
    "            <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "            INSTRUCTIONS:\n",
    "                Given the message: '{message}', map the sentiment to one of the following: {y_labels} based on the context semantic meaning.\n",
    "                Only output the sentiment label in json format.\n",
    "                {output_format}\n",
    "            <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "        \"\"\"\n",
    "\n",
    "print(message)\n",
    "print(ground_truth)\n",
    "print(prompt)\n",
    "response = generate(model, tokenizer, prompt, max_tokens=2048, temp=0.0, verbose=False)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = df.message[1]\n",
    "ground_truth = df.sentiment[1]\n",
    "\n",
    "y_labels = df.sentiment.unique().tolist()\n",
    "\n",
    "def set_prompt(message, y_labels) -> str:\n",
    "    output_format = '{\"sentiment\": \"<label>\"}'\n",
    "    prompt = f\"\"\"\n",
    "                <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "                INSTRUCTIONS:\n",
    "                    Given the message: '{message}', map the sentiment to one of the following: {y_labels} based on the context semantic meaning.\n",
    "                    Your response needs to be one of the element in the list: {y_labels}.\n",
    "                    Only output the sentiment label in json format.\n",
    "                    {output_format}\n",
    "                <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "            \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(prompt, model, tokenizer):\n",
    "    response = generate(model, tokenizer, prompt, max_tokens=2048, temp=0.0, verbose=False)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: Both are excellent technology they are helpful in many ways. For the security purpose both are super.\n",
      "Ground Truth: Curious to dive deeper\n",
      "Predicted Sentiment:  {\"sentiment\": \"Happy\"}\n"
     ]
    }
   ],
   "source": [
    "prompt = set_prompt(message, y_labels)\n",
    "response = get_sentiment(prompt, model, tokenizer)\n",
    "\n",
    "# response = json.loads(response)\n",
    "\n",
    "print(f\"Message: {message}\")\n",
    "print(f\"Ground Truth: {ground_truth}\")\n",
    "print(f\"Predicted Sentiment: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | Curious to dive deeper | Curious to dive deeper\n",
      "1 | Happy | Curious to dive deeper\n",
      "2 | Neutral | Curious to dive deeper\n",
      "3 | Neutral | Curious to dive deeper\n",
      "4 | Neutral | Curious to dive deeper\n",
      "5 | Happy | Curious to dive deeper\n",
      "6 | Surprised | Curious to dive deeper\n",
      "7 | Curious to dive deeper | Curious to dive deeper\n",
      "8 | Happy | Curious to dive deeper\n",
      "9 | Curious to dive deeper | Curious to dive deeper\n",
      "10 | Curious to dive deeper | Curious to dive deeper\n",
      "11 | Curious to dive deeper | Curious to dive deeper\n",
      "12 | Curious to dive deeper | Curious to dive deeper\n",
      "13 | Curious to dive deeper | Happy\n",
      "14 | Surprised | Curious to dive deeper\n",
      "15 | Neutral | Curious to dive deeper\n",
      "16 | Neutral | Curious to dive deeper\n",
      "17 | Happy | Curious to dive deeper\n",
      "18 | Neutral | Curious to dive deeper\n",
      "19 | Curious to dive deeper | Curious to dive deeper\n",
      "20 | Happy | Curious to dive deeper\n",
      "21 | Curious to dive deeper | Curious to dive deeper\n",
      "22 | Curious to dive deeper | Curious to dive deeper\n",
      "23 | Surprised | Curious to dive deeper\n",
      "24 | Surprised | Curious to dive deeper\n",
      "25 | Curious to dive deeper | Curious to dive deeper\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     31\u001b[0m prompt \u001b[38;5;241m=\u001b[39m set_prompt(message, y_labels)\n\u001b[0;32m---> 32\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     response \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response)\n",
      "Cell \u001b[0;32mIn[111], line 23\u001b[0m, in \u001b[0;36mget_sentiment\u001b[0;34m(prompt, model, tokenizer)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_sentiment\u001b[39m(prompt, model, tokenizer):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/splore/lib/python3.11/site-packages/mlx_lm/utils.py:263\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(model, tokenizer, prompt, temp, max_tokens, verbose, formatter, repetition_penalty, repetition_context_size, top_p, logit_bias)\u001b[0m\n\u001b[1;32m    260\u001b[0m tic \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m    261\u001b[0m detokenizer\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 263\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprob\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerate_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepetition_context_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperf_counter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtic\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/splore/lib/python3.11/site-packages/mlx_lm/utils.py:217\u001b[0m, in \u001b[0;36mgenerate_step\u001b[0;34m(prompt, model, temp, repetition_penalty, repetition_context_size, top_p, logit_bias)\u001b[0m\n\u001b[1;32m    215\u001b[0m next_y, next_p \u001b[38;5;241m=\u001b[39m _step(y)\n\u001b[1;32m    216\u001b[0m mx\u001b[38;5;241m.\u001b[39masync_eval(next_y)\n\u001b[0;32m--> 217\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, p\n\u001b[1;32m    218\u001b[0m y, p \u001b[38;5;241m=\u001b[39m next_y, next_p\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from json import JSONDecodeError\n",
    "\n",
    "def set_prompt(message, y_labels) -> str:\n",
    "    output_format = '{\"sentiment\": \"<label>\"}'\n",
    "    prompt = f\"\"\"\n",
    "                <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "                INSTRUCTIONS:\n",
    "                    Given the message: '{message}', map the sentiment to one of the following: {y_labels} based on the context semantic meaning.\n",
    "                    Your response needs to be one of the element in the list: {y_labels}.\n",
    "                    Only output the sentiment label in json format.\n",
    "                    {output_format}\n",
    "                <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "            \"\"\"\n",
    "    return prompt\n",
    "\n",
    "def get_sentiment(prompt, model, tokenizer):\n",
    "    return generate(model, tokenizer, prompt, max_tokens=2048, temp=0.0, verbose=False)\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # if index == 10:\n",
    "    #     break\n",
    "    message = row['message']\n",
    "    ground_truth = row['sentiment']\n",
    "    prompt = set_prompt(message, y_labels)\n",
    "    response = get_sentiment(prompt, model, tokenizer)\n",
    "    try:\n",
    "        response = json.loads(response)\n",
    "        response = response['sentiment']\n",
    "    except JSONDecodeError:\n",
    "        response = response\n",
    "    \n",
    "    print(f\"{index} | {response} | {ground_truth}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from json import JSONDecodeError\n",
    "\n",
    "def set_prompt(message, y_labels) -> str:\n",
    "    output_format = '{\"sentiment\": \"<label>\"}'\n",
    "    prompt = f\"\"\"\n",
    "                <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "                INSTRUCTIONS:\n",
    "                    Given the message: '{message}', map the sentiment to one of the following: {y_labels} based on the context semantic meaning.\n",
    "                    Your response needs to be one of the element in the list: {y_labels}.\n",
    "                    Only output the sentiment label in json format.\n",
    "                    {output_format}\n",
    "                <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "            \"\"\"\n",
    "    return prompt\n",
    "\n",
    "def get_sentiment(prompt, model, tokenizer):\n",
    "    return generate(model, tokenizer, prompt, max_tokens=2048, temp=0.0, verbose=False)\n",
    "\n",
    "def evaluate_and_save_batches(df, y_labels, model, tokenizer, batch_size=1000, output_file=\"predictions.csv\"):\n",
    "    num_batches = len(df) // batch_size + (1 if len(df) % batch_size != 0 else 0)\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        batch = df.iloc[i * batch_size : (i + 1) * batch_size]\n",
    "        ground_truths = batch['sentiment'].tolist()\n",
    "        indices = batch.index.tolist()\n",
    "        messages = batch['message'].tolist()\n",
    "        predictions = []\n",
    "\n",
    "        for idx, message in enumerate(batch['message']):\n",
    "            prompt = set_prompt(message, y_labels)\n",
    "            response = get_sentiment(prompt, model, tokenizer)\n",
    "            \n",
    "            try:\n",
    "                response = json.loads(response)\n",
    "                response = response['sentiment']\n",
    "            except JSONDecodeError:\n",
    "                response = response \n",
    "            \n",
    "            predictions.append(response)\n",
    "            print(f\"{idx} | {response} | {ground_truth}\")\n",
    "\n",
    "        batch_df = pd.DataFrame({'index': indices, 'message':messages, 'y_true': ground_truths, 'y_pred': predictions})\n",
    "        \n",
    "        if i == 0:\n",
    "            batch_df.to_csv(output_file, index=False, mode='w')\n",
    "        else:\n",
    "            batch_df.to_csv(output_file, index=False, mode='a', header=False)\n",
    "        \n",
    "        print(f\"Processed and saved batch {i + 1}/{num_batches}\")\n",
    "\n",
    "def load_and_evaluate(output_file=\"predictions.csv\"):\n",
    "    combined_df = pd.read_csv(output_file)\n",
    "    y_true = combined_df['y_true']\n",
    "    y_pred = combined_df['y_pred']\n",
    "    y_labels = y_true.unique().tolist()\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=y_labels)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=y_labels, yticklabels=y_labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_true, y_pred, target_names=y_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | Curious to dive deeper | Curious to dive deeper\n",
      "1 | Happy | Curious to dive deeper\n",
      "2 | Neutral | Curious to dive deeper\n",
      "3 | Neutral | Curious to dive deeper\n",
      "4 | Neutral | Curious to dive deeper\n",
      "5 | Happy | Curious to dive deeper\n",
      "6 | Surprised | Curious to dive deeper\n",
      "7 | Curious to dive deeper | Curious to dive deeper\n",
      "8 | Happy | Curious to dive deeper\n",
      "9 | Curious to dive deeper | Curious to dive deeper\n",
      "Processed and saved batch 1/5\n",
      "0 | Curious to dive deeper | Curious to dive deeper\n",
      "1 | Curious to dive deeper | Curious to dive deeper\n",
      "2 | Curious to dive deeper | Curious to dive deeper\n",
      "3 | Curious to dive deeper | Curious to dive deeper\n",
      "4 | Surprised | Curious to dive deeper\n",
      "5 | Neutral | Curious to dive deeper\n",
      "6 | Neutral | Curious to dive deeper\n",
      "7 | Happy | Curious to dive deeper\n",
      "8 | Neutral | Curious to dive deeper\n",
      "9 | Curious to dive deeper | Curious to dive deeper\n",
      "Processed and saved batch 2/5\n",
      "0 | Happy | Curious to dive deeper\n",
      "1 | Curious to dive deeper | Curious to dive deeper\n",
      "2 | Curious to dive deeper | Curious to dive deeper\n",
      "3 | Surprised | Curious to dive deeper\n",
      "4 | Surprised | Curious to dive deeper\n",
      "5 | Curious to dive deeper | Curious to dive deeper\n",
      "6 | Surprised | Curious to dive deeper\n",
      "7 | Surprised | Curious to dive deeper\n",
      "8 | Happy | Curious to dive deeper\n",
      "9 | Happy | Curious to dive deeper\n",
      "Processed and saved batch 3/5\n",
      "0 | Surprised | Curious to dive deeper\n",
      "1 | Curious to dive deeper | Curious to dive deeper\n",
      "2 | Happy | Curious to dive deeper\n",
      "3 | Happy | Curious to dive deeper\n",
      "4 | Curious to dive deeper | Curious to dive deeper\n",
      "5 | Happy | Curious to dive deeper\n",
      "6 | Curious to dive deeper | Curious to dive deeper\n",
      "7 | Curious to dive deeper | Curious to dive deeper\n",
      "8 | Curious to dive deeper | Curious to dive deeper\n",
      "9 | Curious to dive deeper | Curious to dive deeper\n",
      "Processed and saved batch 4/5\n",
      "0 | Curious to dive deeper | Curious to dive deeper\n",
      "1 | Happy | Curious to dive deeper\n",
      "2 | Curious to dive deeper | Curious to dive deeper\n",
      "3 | Happy | Curious to dive deeper\n",
      "4 | Happy | Curious to dive deeper\n",
      "5 | Surprised | Curious to dive deeper\n",
      "6 | Curious to dive deeper | Curious to dive deeper\n",
      "7 | Surprised | Curious to dive deeper\n",
      "8 | Surprised | Curious to dive deeper\n",
      "9 | Surprised | Curious to dive deeper\n",
      "Processed and saved batch 5/5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "evaluate_and_save_batches(df[:50], y_labels, model, tokenizer, batch_size=10, output_file=\"predictions.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
